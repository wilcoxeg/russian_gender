---
title: "Exploratory Analysis for Russian MoTR Reading Data"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, echo=TRUE, results='hide', warning=FALSE, message=FALSE, eval=TRUE}
shhh <- suppressPackageStartupMessages # It's a library, so shhh!

shhh(library( mgcv ))
shhh(library(dplyr))
shhh(library(ggplot2))
shhh(library(lme4))
shhh(library(tidymv))
shhh(library(gamlss))
shhh(library(gsubfn))
shhh(library(lmerTest))
shhh(library(tidyverse))
shhh(library(boot))
shhh(library(rsample))
shhh(library(plotrix))
shhh(library(ggrepel))
shhh(library(mgcv))
shhh(library(brms))
shhh(library(bayesplot))
shhh(library(tidyr))
shhh(library(car))
shhh(library(coda))
shhh(library(gridExtra))
shhh(library(posterior))

shhh(library(cmdstanr))
shhh(library(rstan))
shhh(library(rstantools))

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
rstan_options(auto_write = TRUE)
theme_set(theme_bw())
options(digits=4)
options(scipen=999)
set.seed(444)

```


# Read in MoTR Data

```{r Data, echo=TRUE, warning=FALSE, eval=TRUE}

# The path to the data
data_path <- "./data/"
data_names <- list.files(data_path)

# Read in the data from each participant and add to the data frame
motr_df <- data.frame()
for(name in data_names){
  subj <- gsub("reader_", "", gsub("_reading_measures.csv", "", name))
  temp_df <- read.csv(paste0(data_path, "/", name)) %>% mutate(subj_id = subj)
  motr_df <- rbind(motr_df, temp_df)
}


# Turn the data into a tidy dataframe and clean the data
clean_df <- motr_df %>%
  filter(! list %in% c(98, 99)) %>% # filter practice and filler items
  mutate(skip = ifelse(total_duration==0, 1, 0),
         FPReg = ifelse(gaze_duration==0, NA, FPReg),
         FPFix = ifelse(gaze_duration==0, NA, FPFix)) %>%
  filter(skip == 0) %>%
  
  gather(measure, value, 18:26) %>%
  mutate(tgt_zero = if_else(measure %in% c("first_duration", "gaze_duration", "go_past_time", "right_bounded_rt", "total_duration") & value == 0, F, T)) %>%
  filter(tgt_zero != F) %>%
  dplyr::select(-tgt_zero, -cond_id, -skip) %>%
  mutate(item_id = as.factor(item_id),
         subj_id = as.factor(subj_id)) %>%
  mutate(cond = case_when(
    target_gender == "M" & gender_match == "Mis" & type == "stim_adj" ~ "a",
    target_gender == "M" & gender_match == "Mis" & type == "stim_verb" ~ "b",
     target_gender == "M" & gender_match == "Mis" & type == "stim_pred_adj" ~ "c",
    target_gender == "M" & gender_match == "Match" & type == "stim_adj" ~ "d",
    target_gender == "M" & gender_match == "Match" & type == "stim_verb" ~ "e",
    target_gender == "M" & gender_match == "Match" & type == "stim_pred_adj" ~ "f",
    target_gender == "F" & gender_match == "Mis" & type == "stim_adj" ~ "g",
    target_gender == "F" & gender_match == "Mis" & type == "stim_verb" ~ "h",
    target_gender == "F" & gender_match == "Mis" & type == "stim_pred_adj" ~ "i",
    target_gender == "F" & gender_match == "Match" & type == "stim_adj" ~ "j",
    target_gender == "F" & gender_match == "Match" & type == "stim_verb" ~ "k",
    target_gender == "F" & gender_match == "Match" & type == "stim_pred_adj" ~ "l",
    TRUE ~ NA_character_ # This is the default case if none of the above conditions are met
  )) %>%
  dplyr::select(-list, -part, -type, -type_id, -target_gender, -gender_match, -orig_item_number, -case, -animacy, -AOI_id, -word, -response_true, -response_chosen, -correctness)

View(clean_df)

```

```{r Data_visualization, echo=TRUE, eval=TRUE}

clean_df %>% filter(word_nr == 3) %>%
  filter(measure == "go_past_time") %>%
  mutate(index = row_number()) %>%
  ggplot(., aes(x = index, y = value, color = cond)) +
  geom_point(alpha = 0.5) +  # Adjust alpha for better visualization if points overlap
  labs(x = "condition", y = "Go Past Time", title = "Scatter Plot of Go Past Time by Condition") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(0, 2000)  # Set y-axis limits from 0 to 2000
```

### RESEARCH QUESTIONS:
 1. Are RTs different in gender-match versus gender-mismatch sentences?
 ==> main effect of grammaticality (gender match or not)
 
 2. Are RTs different in Masculine versus Feminine sentence conditions?
 ==> main effect of gender of target word
 
 3. Are RTs affected by sentence type (whether different lexical categories of the agreeing element will make the processing more difficult or not)? --> ADJ(adj + pre_adj) v.s. VERB 
 ==> main effect of lexical type of sentences. 
 
 4. Are RTs affected by sentence type (whether agreeing element instantiates internal v.s. external agreement will make a difference in processing difficulty)? --> internal (modifying adjective) v.s. external (verb or predicative adjective)
 ==> main effect of syntax type of sentences.
 
 5. Does the grammaticality effect within each lexical sentence type differ from each other? --> Whether the effect of grammaticality depends on the lexical type of the sentence (ADJ? VERB?)
 ==> interaction between grammaticality and lexical sentence type
 
 6.Does the grammaticality effect within each syntax sentence type differ from each other? --> Whether the effect of grammaticality depends on the syntax type of the sentence (internal? external?)
 ==> interaction between grammaticality and syntax sentence type
 
 7. Does the (possible) difference in the sensitivity to the grammaticality manipulation of 
     Masculine versus Feminine conditions differ between lexical sentence types (ADJ v.s. VERB)?
 ==> 3-way interaction between grammaticality, gender and lexical sentence type
 
 8. Does the (possible) difference in the sensitivity to the grammaticality manipulation of 
     Masculine versus Feminine conditions differ between syntax sentence types (internal v.s. external)?
 ==> 3-way interaction between grammaticality, gender and syntax sentence type


# contrast coding
```{r factorize, echo=TRUE, eval=TRUE}
# check conditions
clean_df$cond <- factor(clean_df$cond)
summary(clean_df$cond)
```

```{r, Contrasts-1, echo=FALSE, eval=FALSE}
# X_H <- matrix(c(1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,    # Intercept
#                 1/6,1/6,1/6,-1/6,-1/6,-1/6,1/6,1/6,1/6,-1/6,-1/6,-1/6, # Main effect grammaticality 
#                 1/6,1/6,1/6,1/6,1/6,1/6,-1/6,-1/6,-1/6,-1/6,-1/6,-1/6, # Main effect gender
#                 1/4,-1/4,0,1/4,-1/4,0,1/4,-1/4,0,1/4,-1/4,0, # Main effect of sentence type (av)
#                 0,1/4,-1/4,0,1/4,-1/4,0,1/4,-1/4,0,1/4,-1/4, # Main effect of sentence type (vp)
#                 1/4,-1/4,0,-1/4,1/4,0,1/4,-1/4,0,-1/4,1/4,0,# Grammaticality x type (av)
#                 0,1/4,-1/4,0,-1/4,1/4,0,1/4,-1/4,0,-1/4,1/4, # Grammaticality x type (vp)
#                 1/6,1/6,1/6,-1/6,-1/6,-1/6,-1/6,-1/6,-1/6,1/6,1/6,1/6, # Grammaticality x gender
#                 1/4,-1/4,0,1/4,-1/4,0,-1/4,1/4,0,-1/4,1/4,0, # gender x type (av)
#                 0,1/4,-1/4,0,1/4,-1/4,0,-1/4,1/4,0,-1/4,1/4, # gender x type (vp)
#                 1/4,-1/4,0,-1/4,1/4,0,-1/4,1/4,0,1/4,-1/4,0, # Grammaticality x gender x type (av)
#                 0,1/4,-1/4,0,-1/4,1/4,0,-1/4,1/4,0,1/4,-1/4  # Grammaticality x gender x type (vp)
# ), byrow=TRUE, nrow = 12)

X_H <- matrix(c(1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,1/12,    # Intercept
                1/6,1/6,1/6,-1/6,-1/6,-1/6,1/6,1/6,1/6,-1/6,-1/6,-1/6, # Main effect grammaticality 
                1/6,1/6,1/6,1/6,1/6,1/6,-1/6,-1/6,-1/6,-1/6,-1/6,-1/6, # Main effect gender
                1/8,-1/4,1/8,1/8,-1/4,1/8,1/8,-1/4,1/8,1/8,-1/4,1/8, # Main effect of sentence type (ap vs v)
                1/4,-1/8,-1/8,1/4,-1/8,-1/8,1/4,-1/8,-1/8,1/4,-1/8,-1/8, # Main effect of sentence type (a vs pv)
                1/8,-1/4,1/8,-1/8,1/4,-1/8,1/8,-1/4,1/8,-1/8,1/4,-1/8,# Grammaticality x type (ap v)
                1/4,-1/8,-1/8,-1/4,1/8,1/8,1/4,-1/8,-1/8,-1/4,1/8,1/8, # Grammaticality x type (a pv)
                # 1/4,-1/2,1/4,0,0,0,1/4,-1/2,1/4,0,0,0, # type_Mis
                # 0,0,0,1/4,-1/2,1/4,0,0,0,1/4,-1/2,1/4, # type_Match
                # 1/2,-1/2,1/2,0,0,0,-1/2,1/2,-1/2,0,0,0, # gen x typ1(ap v)_Mis
                # 1/2,-1/2,-1/2,0,0,0,-1/2,1/2,1/2,0,0,0, # gen x typ2(a pv)_Mis
                # 0,0,0,1/2,-1/2,1/2,0,0,0,-1/2,1/2,-1/2, # gen x typ1(ap v)_Match
                # 0,0,0,1/2,-1/2,-1/2,0,0,0,-1/2,1/2,1/2, # gen x typ2(a pv)_Match
                # 1/2,-1/2,1/2,-1/2,1/2,-1/2,0,0,0,0,0,0, # gram x typ1(ap v)_M
                # 1/2,-1/2,-1/2,-1/2,1/2,1/2,0,0,0,0,0,0, # gram x typ2(a pv)_M
                # 0,0,0,0,0,0,1/2,-1/2,1/2,-1/2,1/2,-1/2, # gram x typ1(ap v)_F
                # 0,0,0,0,0,0,1/2,-1/2,-1/2,-1/2,1/2,1/2 # gram x typ2(a pv)_F
                1/2,-1/2,1/2,-1/2,1/2,-1/2,-1/2,1/2,-1/2,1/2,-1/2,1/2, # gen x typ1(ap v) x gram
                1/2,-1/2,-1/2,-1/2,1/2,1/2,-1/2,1/2,1/2,1/2,-1/2,-1/2, # gen x typ2(a pv) x gram
                0,0,0,0,0,0,0,0,0,0,0,0,
                0,0,0,0,0,0,0,0,0,0,0,0,
                0,0,0,0,0,0,0,0,0,0,0,0
                
), byrow=TRUE, nrow = 12)

X_H
X_C = ginv(X_H)
rownames(X_C) <- c('a','b','c','d','e','f','g','h', 'i', 'j', 'k', 'l')
colnames(X_C) <- c('Intercept','Gram','Gen', 'Typ1', 'Typ2', 'Gram_x_Typ1', 'Gram_x_Typ2', 'Gen_x_Typ1_x_Gram', 'Gen_x_Typ2_x_Gram', '9', '10', '11')
X_C
X_C_bar <- X_C[,2:ncol(X_C)]
X_C_bar

contrasts(clean_df$cond)
contrasts(clean_df$cond) <- X_C_bar
contrasts(clean_df$cond)

```

```{r Contrasts-2, echo=TRUE, eval=TRUE}
clean_df <- clean_df %>% 
  mutate(
    #--------------------- main effects ---------------------
    Gram = ifelse(cond %in% c('a', 'b', 'c', 'g', 'h', 'i'), 1/6, -1/6), # Main effect grammaticality 
    Gen = ifelse(cond %in% c('a','b','c','d','e', 'f'), 1/6, -1/6), # Main effect gender
    TypL = ifelse(cond %in% c('a','c','d','f', 'g', 'i', 'j', 'l'), 1/8, -1/4), # Main effect of sentence type (ap vs v)
    TypS = ifelse(cond %in% c('a', 'd', 'g', 'j'), 1/4, -1/8), # Main effect of sentence type (a vs pv)
    
    #--------------------- 2 way interection ---------------------
    # Gram_x_TypL = ifelse(cond %in% c('a', 'c', 'i'), 1/8,
    #                  ifelse(cond %in% c('d', 'f', 'l'), -1/8,
    #                    ifelse(cond %in% c('e', 'k'), 1/4, -1/4))), # Grammaticality x type (ap v)
    
    # Gram_x_TypS = ifelse(cond %in% c('e', 'f', 'k', 'l'), 1/8,
    #                   ifelse(cond %in% c('b', 'c', 'h', 'i'), -1/8,
    #                          ifelse(cond %in% c('a', 'g'), 1/4, -1/4))), # Grammaticality x type (ap v)
    
    Gram_x_TypL = ifelse(cond %in% c('a', 'c', 'g', 'i', 'e', 'k'), 1/2, -1/2), # Grammaticality x type (ap v)
    Gram_x_TypS = ifelse(cond %in% c('a', 'g', 'e', 'f', 'k', 'l'), 1/2, -1/2), # Grammaticality x type (a pv)

    Gram_TypL_M = ifelse(cond %in% c('a', 'c', 'e'), 1/2, 
                    ifelse(cond %in% c('b', 'd', 'f'), -1/2, 0)), # gram x typl(ap v)_M
    Gram_TypS_M = ifelse(cond %in% c('a', 'e', 'f'), 1/2, 
                ifelse(cond %in% c('b', 'c', 'd'), -1/2, 0)), # gram x typs(a pv)_M
    Gram_TypL_F = ifelse(cond %in% c('g', 'i', 'k'), 1/2, 
                ifelse(cond %in% c('h', 'j', 'l'), -1/2, 0)), # gram x typl(ap v)_F
    Gram_TypS_F = ifelse(cond %in% c('a', 'e', 'f'), 1/2, 
                ifelse(cond %in% c('b', 'c', 'd'), -1/2, 0)), # gram x typs(a pv)_F
    
    #--------------------- 3 way interection ---------------------
    Gram_x_Gen_x_TypL = ifelse(cond %in% c('a', 'c', 'e', 'h', 'j', 'l'), 1/2, -1/2), # gen x typ1(ap v) x gram
    Gram_x_Gen_x_TypS = ifelse(cond %in% c('a', 'e', 'f', 'h', 'i', 'j'), 1/2, -1/2), # gen x typ1(ap v) x gram
    
    #--------------------- Within grammaticality type effects ---------------------
    Typ_Mis = ifelse(cond %in% c('a', 'c', 'g', 'i'), 1/4,
              ifelse(cond %in% c('b', 'h'), -1/2, 0)),  # type_Mis
    Typ_Match = ifelse(cond %in% c('d', 'f', 'j', 'l'), 1/4,
                  ifelse(cond %in% c('e', 'k'), -1/2, 0))  # type_Match
  ) %>% spread(measure, value) %>%
  filter(word_nr == 3)
  
clean_df
```

```{r lmer_models, echo=TRUE, eval=FALSE, message=FALSE}
stats_df = data.frame()
measure_types = c("gaze_duration", "go_past_time", "total_duration", 
                  "FPReg", "RegIn_incl"
                  )

for (meas in measure_types){
  print(paste("Fitting model for:", meas))
  
  if (meas %in% c("gaze_duration", "go_past_time", "total_duration")){
      model <- clean_df %>% filter(!is.na(.[[meas]]))  %>% 
        lmer(as.formula(paste(meas, "~ Gram + Gen + TypL + TypS + 
            Gram_x_TypL + Gram_x_TypS + Gram_x_Gen_x_TypL + Gram_x_Gen_x_TypS + 
            (Gram | item_id) + (Gram | subj_id)")), 
            data = ., REML = F)
      coefs <- summary(model)$coefficients
      temp_results <- data.frame(
        measure = meas,
        beta = c("b_0", "b_Gram", "b_Gen", "b_TypL", "b_TypS", "b_Gram_x_TypL", "b_Gram_x_TypS", "b_Gram_x_Gen_x_TypL", "b_Gram_x_Gen_x_TypS"),
        bval = coefs[, "Estimate"],
        pval = coefs[, "Pr(>|t|)"]
      )
  }else{
      model <- clean_df %>% filter(!is.na(.[[meas]]))  %>% 
        glmer(as.formula(paste(meas, "~ Gram + Gram_x_TypL + Gram_x_TypS + Gram_x_Gen_x_TypL + Gram_x_Gen_x_TypS + 
            (1 | item_id) + (1 | subj_id)")), 
            data = ., family=binomial(link = "logit"))
      coefs <- summary(model)$coefficients
      temp_results <- data.frame(
        measure = meas,
        beta = c("b_0", "b_Gram", "b_Gram_x_TypL", "b_Gram_x_TypS", "b_Gram_x_Gen_x_TypL", "b_Gram_x_Gen_x_TypS"),
        bval = coefs[, "Estimate"],
        pval = coefs[, "Pr(>|z|)"]
        )
  }
    stats_df = rbind(stats_df, temp_results)
}

stats_df = stats_df %>%
  mutate(sig = if_else(pval < 0.05, "SIG", ifelse(pval < .1, ".", "")))

# stats_df

write.csv(stats_df, "./stats/stats_lmer.csv", row.names = FALSE)

# m_gd <- clean_df %>%
#   filter(!is.na(FPReg)) %>%
#   glmer(FPReg ~ Gram + Gram_x_TypL+ Gram_x_TypS + Gram_x_Gen_x_TypL + Gram_x_Gen_x_TypS +
#          (1 | item_id ) + (1 | subj_id ), data = ., family=binomial(link = "logit"))
# summary(m_gd)$coefficients

```

# function for creating stan data format
```{r createStanDat, echo=TRUE, eval=TRUE}
createStanDat<-function(d, dv,form){
  
  subj <- as.integer(factor(d$subj))
  N_subj <- length(unique(subj))
  item <- as.integer(factor(d$item))
  N_items <- length(unique(item))
  X <- unname(model.matrix(form, d))  
  attr(X, which="assign") <- NULL
  
  stanDat <- list(N = nrow(X),           
                  P = ncol(X),              
                  n_u = ncol(X),             
                  n_w = ncol(X),            
                  X = X,                     
                  Z_u = X,                 
                  Z_w = X,                   
                  J = N_subj,                
                  K = N_items,
                  dv = dv,                    
                  subj = subj,
                  item = item)
  stanDat
}
```


```{r stan_gaze_duration, echo=TRUE, eval=False}
stan_gd <- createStanDat(d=subset(clean_df, !is.na(clean_df$gaze_duration)),
                             form=as.formula("~1+Gram+Gen+TypL+TypS+Gram_x_TypL+Gram_x_TypS+Gram_x_Gen_x_TypL+Gram_x_Gen_x_TypS"), 
                             dv=subset(clean_df, !is.na(clean_df$gaze_duration))$gaze_duration)

m1_gd <- stan(file = "stan/maxModel1.stan", 
                data = stan_gd,
                iter = 4000, 
                chains = 4,
                control = list(adapt_delta=0.99))
saveRDS(m1_gd, file = "model/m1_gd.rds")
```


```{r stan_go_past_time, echo=TRUE, eval=False}
stan_gpt <- createStanDat(d=subset(clean_df, !is.na(clean_df$go_past_time)),
                             form=as.formula("~1+Gram+Gen+TypL+TypS+Gram_x_TypL+Gram_x_TypS+Gram_x_Gen_x_TypL+Gram_x_Gen_x_TypS"), 
                             dv=subset(clean_df, !is.na(clean_df$go_past_time))$go_past_time)

# sample from posterior distribution.
m1_gpt <- stan(file = "stan/maxModel1.stan", 
                data = stan_gpt,
                iter = 4000, 
                chains = 4,
                control = list(adapt_delta=0.99))
saveRDS(m1_gpt, file = "model/m1_gpt.rds")
```


```{r stan_total_duration, echo=TRUE, eval=False}
stan_td <- createStanDat(d=subset(clean_df, !is.na(clean_df$total_duration)),
                             form=as.formula("~1+Gram+Gen+TypL+TypS+Gram_x_TypL+Gram_x_TypS+Gram_x_Gen_x_TypL+Gram_x_Gen_x_TypS"), 
                             dv=subset(clean_df, !is.na(clean_df$total_duration))$total_duration)

# sample from posterior distribution.
m1_td <- stan(file = "stan/maxModel1.stan", 
                data = stan_td,
                iter = 4000, 
                chains = 4,
                control = list(adapt_delta=0.99))
saveRDS(m1_td, file = "model/m1_td.rds")
```

# binary dv
```{r stan_FPReg, echo=TRUE, eval=False}
stan_fpreg <- createStanDat(d=subset(clean_df, !is.na(clean_df$FPReg)),
                             form=as.formula("~1+Gram+Gen+TypL+TypS+Gram_x_TypL+Gram_x_TypS+Gram_x_Gen_x_TypL+Gram_x_Gen_x_TypS"), 
                             dv=subset(clean_df, !is.na(clean_df$FPReg))$FPReg)

# sample from posterior distribution.
m1_fpreg <- stan(file = "stan/logitModel1.stan", 
                data = stan_fpreg,
                iter = 4000, 
                chains = 4,
                control = list(adapt_delta=0.99))
saveRDS(m1_fpreg, file = "model/m1_fpreg.rds")
```


```{r stan_Regin_incl, echo=TRUE, eval=False}
stan_regin <- createStanDat(d=subset(clean_df, !is.na(clean_df$RegIn_incl)),
                             form=as.formula("~1+Gram+Gen+TypL+TypS+Gram_x_TypL+Gram_x_TypS+Gram_x_Gen_x_TypL+Gram_x_Gen_x_TypS"), 
                             dv=subset(clean_df, !is.na(clean_df$RegIn_incl))$RegIn_incl)

# sample from posterior distribution.
m1_regin <- stan(file = "stan/logitModel1.stan", 
                data = stan_regin,
                iter = 4000, 
                chains = 4,
                control = list(adapt_delta=0.99))
saveRDS(m1_regin, file = "model/m1_regin.rds")
```


# Examine fitted stan models
```{r Model_examination, echo=TRUE, eval=False}
# change m1_gd.rds to other models to check them

m1_gd <- readRDS("model/m1_fpreg.rds")

# check params
summary(m1_gd, pars = c('beta[1]', 'beta[2]', 'beta[3]', 'beta[4]', 'beta[5]', 'beta[6]', 'beta[7]', 'beta[8]', 'beta[9]'))

# check convergence
traceplot(m1_gd, pars = c("beta"))

# check predicts --> posterior parameter distr.
y_posterior <- extract(m1_gd) 
y_posterior$beta[,1] #intercept
y_posterior$beta[,2] #Gram
y_posterior$beta[,3] #Gen
y_posterior$beta[,4] #TypL
y_posterior$beta[,5] #TypS
y_posterior$beta[,6] #Gram_x_TypL
y_posterior$beta[,7] #Gram_x_TypS

# check predicts --> posterior parameter distr. back in normal space
pst_gram <- y_posterior$Gram
pst_gram
density_gram <- density(pst_gram)
plot(density_plot, main = "Density Plot of pst_gram", xlab = "pst_gram values", ylab = "Density", col = "red")

pst_gen <- y_posterior$Gen
pst_gen
density_gen <- density(pst_gen)
plot(density_gen, main = "Density Plot of pst_gen", xlab = "pst_gen values", ylab = "Density", col = "red")

pst_typl <- y_posterior$TypL
pst_typl
density_typl <- density(pst_typl)
plot(density_typl, main = "Density Plot of pst_typl", xlab = "pst_typl values", ylab = "Density", col = "red")

pst_typs <- y_posterior$TypS
pst_typs
density_typs <- density(pst_typs)
plot(density_typs, main = "Density Plot of pst_typs", xlab = "pst_typs values", ylab = "Density", col = "red")

pst_gramxtypl <- y_posterior$Gram_x_TypL
pst_gramxtypl
density_gramxtypl <- density(pst_gramxtypl)
plot(density_gramxtypl, main = "Density Plot of pst_gramxtypl", xlab = "pst_gramxtypl values", ylab = "Density", col = "red")

pst_gramxtyps <- y_posterior$Gram_x_TypS
pst_gramxtyps
density_gramxtyps <- density(pst_gramxtyps)
plot(density_gramxtyps, main = "Density Plot of pst_gramxtyps", xlab = "pst_gramxtyps values", ylab = "Density", col = "red")

pst_gramxgenxtypl <- y_posterior$Gram_x_Gen_x_TypL
pst_gramxgenxtypl
density_gramxgenxtypl <- density(pst_gramxgenxtypl)
plot(density_gramxgenxtypl, main = "Density Plot of pst_gramxgenxtypl", xlab = "pst_gramxgenxtypl values", ylab = "Density", col = "red")


pst_gramxgenxtyps <- y_posterior$Gram_x_Gen_x_TypS
pst_gramxgenxtyps
density_gramxgenxtyps <- density(pst_gramxgenxtyps)
plot(density_gramxgenxtyps, main = "Density Plot of pst_gramxgenxtyps", xlab = "pst_gramxgenxtyps values", ylab = "Density", col = "red")


# check posterior predicts --> the fits looks very good --> suspision of overfit? --> cv validation?
predicts <- y_posterior$Predict_rt
dim(predicts) # 8000 x 1271
y_true <- subset(clean_df, !is.na(clean_df$FPReg))$FPReg
ppc_dens_overlay(y_true, yrep = predicts[1:200, ])

```

# compile model results
```{r compile_restuls, echo=TRUE, eval=TRUE}
stats_df <- data.frame()

# Define the measure types corresponding to your models
measure_types <- c("gaze_duration", "go_past_time", "total_duration", "FPReg", "RegIn_incl")

# Loop over each measure type to read the corresponding model and extract data
for (meas in measure_types) {
  if (meas == "gaze_duration") {
      m1 <- readRDS("model/m1_gd.rds")
    } else if (meas == "go_past_time") {
      m1 <- readRDS("model/m1_gpt.rds")
    } else if (meas == "total_duration") {
      m1 <- readRDS("model/m1_td.rds")
    } else if (meas == "FPReg") {
      m1 <- readRDS("model/m1_fpreg.rds")
    } else if (meas == "RegIn_incl") {
      m1 <- readRDS("model/m1_regin.rds")
    }

  # Extract posterior distributions
  y_posterior <- extract(m1)
  intercept <- exp(y_posterior$beta[,1])

  betas <- c("b_0", "b_Gram", "b_Gen", "b_TypL", "b_TypS", "b_Gram_x_TypL", "b_Gram_x_TypS", "b_Gram_x_Gen_x_TypL", "b_Gram_x_Gen_x_TypS")
  posterior_samples <- list(intercept, y_posterior$Gram, y_posterior$Gen, y_posterior$TypL, y_posterior$TypS,    y_posterior$Gram_x_TypL, y_posterior$Gram_x_TypS, y_posterior$Gram_x_Gen_x_TypL, y_posterior$Gram_x_Gen_x_TypS)

  # Prepare the results data frame
  temp_results <- data.frame(
    measure = rep(meas, length(betas)),
    beta = betas,
    bval_mean = sapply(posterior_samples, mean),
    crI_95_lower = sapply(posterior_samples, function(x) quantile(x, 0.025)),
    crI_95_upper = sapply(posterior_samples, function(x) quantile(x, 0.975)),
    crl_89_lower = sapply(posterior_samples, function(x) quantile(x, 0.055)),
    crl_89_upper = sapply(posterior_samples, function(x) quantile(x, 0.945)),
    bval_median = sapply(posterior_samples, median)
  )

  # Append the temp_results to the stats_df data frame
  stats_df <- rbind(stats_df, temp_results)
}

write.csv(stats_df, "./stats/stats_bayesian.csv", row.names = FALSE)
```

### OBSERVATIONS:

gpt, gd, td, reg: 

1. Effects of Grammaticality are always significant. --> There are main effect of grammaticality (gender match or not).
2. Effects of condTypS are significant or nearly significant. --> Very likely, there are main effect of syntactic agreement type (adj vs verb & pred_adj)

3. The significance of condTypL is always smaller than condTypS. In Bayesian, the crI of beta for TypL (diff between adj vs verb) is always larger and 0 is more to the middle of its distribution.
* If do sum contrast for each level of type, pred_adj type is significantly different from the grand mean.

4. For gd, the interaction between TypS and Gram is significant. For td and gpt, it is also near to significance (or 0 to be in the narrow tail of its distr. in Bayesian). --> external or internal agreement will affect the process of mismatches in sentence.

5. Interaction between TypL and Gram is far from significance.

6. In td, there are three way interaction between TypL & Gram & Gen. --> coincidence? 

### CONCLUSION:

1. Longer rt and more regressions in error setences.
2. Longer rt and possibly more regressions in external agreement than internal ones. --> external is more difficult.
3. But rt difference between mismatch and match is bigger in internal than in external. --> internal agreement kind of amplify the processing difficulty in mismatches. Maybe because external sentences are already difficult, so when combined with errors, the rt is not that different from in correct sentence. Maybe because people have their upboundary for the times they spend on difficult sentences? --> obviously, rt(difficult_external_type + error_sentence) < rt(difficult_external_type_sentence) + rt(error_sentence)


```{r Original_data_analysis, echo=FALSE, eval=FALSE}

# Run a model for each category in the data (for each stimulus type, measurement and target gender)

stim_types = c("stim_adj", "stim_pred_adj", "stim_verb")
measure_types = c("gaze_duration", "go_past_time", "total_duration")
target_genders = c("M", "F")

stats_df = data.frame()
for(stim in stim_types){
  for (meas in measure_types){
    #for(gend in target_genders){
    
      #model = clean_df %>% filter(type == stim, measure == meas, target_gender == gend, word_nr == 3) %>%
      # model = clean_df %>% filter(type == stim, measure == meas, word_nr == 3) %>%
      model = clean_df %>% filter(type == stim, measure == meas, AOI_id == "R3") %>%
        mutate(gender_match = if_else(gender_match == "Mis", 1, -1),
               item_id = as.factor(item_id),
               target_ismale = if_else(target_gender == "M", 1, 0)) %>%
        # lmer(value ~ gender_match + (gender_match | item_id ) + (gender_match | subj_id ) + (gender_match | target_ismale ), data = ., REML=F)
        lmer(value ~ gender_match + (gender_match | subj_id ) + (gender_match | target_ismale ), data = ., REML=F)
      #temp_results = data.frame(stim = stim, target_gender = gend, measure = meas, beta = summary(model)$coefficients[2], pval = summary(model)$coefficients[10])
      temp_results = data.frame(stim = stim, measure = meas, beta = summary(model)$coefficients[2], pval = summary(model)$coefficients[10])

  
      stats_df = rbind(stats_df, temp_results)
    
    #}
  }
}

stats_df = stats_df %>%
  mutate(sig = if_else(pval < 0.05 & beta > 0, "SIG", ""))

stats_df

```


```{r}
# Create an aggregate DF with mean and 95% CIs for each condition and sentence region

df = motr_df %>%
  filter(! list %in% c(98, 99)) %>% # filter practice and filler items
  mutate(skip = ifelse(total_duration==0, 1, 0),
         FPReg = ifelse(gaze_duration==0, NA, FPReg),
         FPFix = ifelse(gaze_duration==0, NA, FPFix)) %>%
  filter(skip == 0) %>%
  
  gather(measure, value, 18:26) %>%
  mutate(tgt_zero = if_else(measure %in% c("first_duration", "gaze_duration", "go_past_time", "right_bounded_rt", "total_duration") & value == 0, F, T)) %>%
  filter(tgt_zero != F) %>%
  drop_na() %>%
  dplyr::select(-tgt_zero, -cond_id, -skip) %>%
  
  mutate(word_nr = if_else(word_nr > 4, 4, as.double(word_nr))) %>%
  rename(region = word_nr) %>%
  #mutate(region=factor(region, levels=c("pre-critical", "critical", "post-critical", "end"))) %>%
  mutate(type_s = ifelse(type %in% c('stim_adj'), "Modifying_Adj", "Predictive_Adj_Verb"),
         type_l = ifelse(type %in% c('stim_verb'), "Verb", "Modifying_Adj_Predictive_Adj")
         ) %>%
  drop_na() %>%
  group_by(measure) %>%
    mutate(outlier = value > (mean(value) + 3 * sd(value))) %>%
  ungroup() %>%
  mutate(outlier_discard = if_else(measure %in% c("first_duration", "gaze_duration", "total_duration", "go_past_time", "right_bounded_rt") & outlier == T, F, T)) %>%
  filter(outlier_discard == T) %>%
  dplyr::select(-outlier_discard) %>%
  drop_na()
  
# View(df)

agg_df = df %>%
  group_by(type_s, gender_match, region, measure) %>%
    summarise(
      m = mean(value),
      s = std.error(value),
      lower = m - 1.96 * s,
      upper = m + 1.96 * s
    ) %>%
  ungroup()

agg_df 

```
```{r}

# Plot the reading times in each region broken down by stimulus type, reading measure and target gender

agg_df %>%
  # filter(type_s %in% c("stim_adj", "stim_verb", "stim_pred_adj")) %>%
  filter(measure %in% c("gaze_duration", "go_past_time", "total_duration")) %>%
  
  mutate(type_s = factor(type_s, levels = c("Modifying_Adj", "Predictive_Adj_Verb"), labels=c("Modifying Adjective", "Predicative Adj. & Verb"))) %>%
  mutate(measure = factor(measure, levels = c("gaze_duration", "go_past_time", "total_duration"), labels=c("Gaze Duration", "Go Past Times", "Total Duration"))) %>%

  ggplot(aes(x=region, y=m, color = gender_match)) +
    geom_rect(aes(xmin=2.5, xmax=3.5, ymin=lower-100, ymax=upper+100), color = NA, fill = "green", alpha=0.01) +
    geom_point() +
    geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.2) +
    geom_line() +
    facet_grid(measure~type_s, scales = "free_y") +
    #ggtitle(paste0("Region by region plot for ", stim)) +
    ylab("Reading time in ms") +
    xlab("Word Number") +
  #coord_cartesian(ylim=c(0, 900)) +
  theme(
    legend.position = "bottom"
  )

ggsave(paste0("./images/RT_results_synt_position.pdf"), device="pdf", height=5, width=8)
# ggsave(paste0("./images/RT_results.png"), height=5, width=8)



```

```{r}
agg_df2 = df %>%
  group_by(type_s, subj_id, region, measure) %>%
    summarise(
      m = mean(value),
    ) %>%
  ungroup() %>%
  group_by(type_s, region, measure) %>%
  pivot_wider(
    names_from = type_s,
    values_from = m,
    names_prefix = "mean_"
  ) %>%
  # Calculate the difference between 'Mis' and 'Match'
  drop_na() %>%
  mutate(
    diff = mean_Predictive_Adj_Verb - mean_Modifying_Adj
  ) %>%
  group_by(region, measure) %>%
  summarise(
    m_diff = mean(diff),
    s = std.error(diff),
    lower = m_diff - 1.96 * s,
    upper = m_diff + 1.96 * s
  ) %>%
  ungroup()

# View(agg_df2)
```

```{r}
# Plot the reading times in each region broken down by stimulus type, reading measure and target gender

agg_df2 %>%
  # filter(type_s %in% c("stim_adj", "stim_verb", "stim_pred_adj")) %>%
  filter(measure %in% c("gaze_duration", "go_past_time", "total_duration")) %>%
  mutate(measure = factor(measure, levels = c("gaze_duration", "go_past_time", "total_duration"), labels=c("Gaze Duration", "Go Past Times", "Total Duration"))) %>%

  ggplot(aes(x=region, y=m_diff, color = measure)) +
    geom_rect(aes(xmin=2.5, xmax=3.5, ymin=lower-100, ymax=upper+100), color = NA, fill = "green", alpha=0.01) +
    geom_point() +
    geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.2) +
    geom_line() +
    facet_wrap(~ measure, scales = "free_y") +
    labs(
      title = "Difference in RTs: \nexternal (verb or predicative adjective) vs internal agreement (modifying adjective)",
      y = "Reading time difference (ms)",
      x = "Word Number",
      color = "Measure"
    ) +
  #coord_cartesian(ylim=c(0, 900)) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5)
  )

ggsave(paste0("./images/RT_results_main_diff_in_synt.pdf"), device="pdf", height=5, width=8)
# ggsave(paste0("./images/RT_results.png"), height=5, width=8)
```

```{r}
# Plot the reading times in each region broken down by stimulus type, reading measure and target gender

agg_df2 %>%
  # filter(type_s %in% c("stim_adj", "stim_verb", "stim_pred_adj")) %>%
  filter(measure %in% c("FPReg", "RegIn_incl")) %>%
  mutate(measure = factor(measure, levels = c("FPReg", "RegIn_incl"), labels=c("First Pass Regression out Prob.", "Regression in Prob."))) %>%

  ggplot(aes(x=region, y=m_diff, color = measure)) +
    geom_rect(aes(xmin=2.5, xmax=3.5, ymin=-0.2, ymax=0.2), color = NA, fill = "green", alpha=0.01) +
    geom_point() +
    geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.2) +
    geom_line() +
    facet_wrap(~ measure, scales = "free_y") +
    labs(
      title = "Difference in Regressions: \nexternal (verb or predicative adjective) vs internal agreement (modifying adjective)",
      y = "Regression difference (ms)",
      x = "Word Number",
      color = "Measure"
    ) +
  #coord_cartesian(ylim=c(0, 900)) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5)
  )

ggsave(paste0("./images/Reg_results_main_diff_in_synt.pdf"), device="pdf", height=5, width=8)
# ggsave(paste0("./images/RT_results.png"), height=5, width=8)
```


```{r}
agg_df3 = df %>%
  group_by(type_s, gender_match, item_id, region, measure) %>%
    summarise(
      m = mean(value)
    ) %>%
  ungroup() %>%
  group_by(type_s, region, measure) %>%
  pivot_wider(
    names_from = gender_match,
    values_from = m,
    names_prefix = "mean_"
  ) %>%
  # Calculate the difference between 'Mis' and 'Match'
  drop_na() %>%
  mutate(
    diff = mean_Mis - mean_Match
  ) %>%
  group_by(type_s, region, measure) %>%
  summarise(
    m_diff = mean(diff),
    s = std.error(diff),
    lower = m_diff - 1.96 * s,
    upper = m_diff + 1.96 * s
  ) %>%
  ungroup()

# View(agg_df3)
```

```{r}
# Plot the reading times in each region broken down by stimulus type, reading measure and target gender

agg_df3 %>%
  # filter(type_s %in% c("stim_adj", "stim_verb", "stim_pred_adj")) %>%
  filter(measure %in% c("gaze_duration", "go_past_time", "total_duration")) %>%
  
  mutate(type_s = factor(type_s, levels = c("Modifying_Adj", "Predictive_Adj_Verb"), labels=c("Modifying Adjective", "Predicative Adj. & Verb"))) %>%
  mutate(measure = factor(measure, levels = c("gaze_duration", "go_past_time", "total_duration"), labels=c("Gaze Duration", "Go Past Times", "Total Duration"))) %>%

  ggplot(aes(x=region, y=m_diff, color = type_s)) +
    geom_rect(aes(xmin=2.5, xmax=3.5, ymin=lower-100, ymax=upper+100), color = NA, fill = "green", alpha=0.01) +
    geom_point() +
    geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.2) +
    geom_line() +
    facet_wrap(~ measure, scales = "free_y") +
    #ggtitle(paste0("Region by region plot for ", stim)) +
    labs(
      title = "Difference in RTs under Mismatch and Match conditions",
      y = "Reading time difference (ms)",
      x = "Word Number",
      color = "Agreement Type"
    ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5)
  )

ggsave(paste0("./images/RT_results_interaction_in_synt.pdf"), device="pdf", height=5, width=8)
# ggsave(paste0("./images/RT_results.png"), height=5, width=8)
```

```{r}
agg_df3 %>%
  # filter(type_s %in% c("stim_adj", "stim_verb", "stim_pred_adj")) %>%
  filter(measure %in% c("FPReg", "RegIn_incl")) %>%
  
  mutate(type_s = factor(type_s, levels = c("Modifying_Adj", "Predictive_Adj_Verb"), labels=c("Modifying Adjective", "Predicative Adj. & Verb"))) %>%
  mutate(measure = factor(measure, levels = c("FPReg", "RegIn_incl"), labels=c("First Pass Regression out Prob.", "Regression in Prob."))) %>%

  ggplot(aes(x=region, y=m_diff, color = type_s)) +
    geom_rect(aes(xmin=2.5, xmax=3.5, ymin=-0.3, ymax=0.3), color = NA, fill = "green", alpha=0.01) +
    geom_point() +
    geom_errorbar(aes(ymin=lower, ymax=upper), width = 0.2) +
    geom_line() +
    facet_wrap(~ measure, scales = "free_y") +
    #ggtitle(paste0("Region by region plot for ", stim)) +
    labs(
      title = "Difference in RTs under Mismatch and Match conditions",
      y = "Reading time difference (ms)",
      x = "Word Number",
      color = "Agreement Type"
    ) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(hjust = 0.5)
  )

ggsave(paste0("./images/Regression_results_interaction_in_synt.pdf"), device="pdf", height=5, width=8)
```

